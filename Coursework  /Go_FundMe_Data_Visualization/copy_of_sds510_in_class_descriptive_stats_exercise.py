# -*- coding: utf-8 -*-
"""Copy of SDS510 - In-Class Descriptive Stats Exercise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a98c-ZQJ1gjuWtc0AxMfAwGR7cAR124i

# Descriptive Stastics in Python Exercise - Module 1

In this exercise we will use a dataset related to a collection of individual fundraising campaigns created via the [GoFundMe](https://gofundme.com) website. The data comes from a [project on Github](https://github.com/lmeninato/GoFundMe/) which collected information about GoFundMe projects in 2018.

You will apply your knowledge of descriptive stastics and skills from the data wrangling course to summarize information about specific categories of projects. I've stubbed out a series of steps below. I will describe each task and leave an open code block for you to complete the task. Please use text blocks to summarize your analysis. Use your own knowledge and the [Module 1 example descriptive stats notebook](https://github.com/digitalshawn/STC551/blob/main/Module%201/Descriptive%20Stats%20Example.ipynb) as a guide, but you may use other techniques to answer the prompts.

# Let's Get Started!

### Task hints

*   `instructions in this style require you to write and execute python code in a code block`
*   instructions in this style require you to write a summary, analysis, or explanation in a text block




Here we load the modules we will use in this script. They are the same modules that are used in the [example notebook](https://github.com/digitalshawn/STC551/blob/main/Module%201/Descriptive%20Stats%20Example.ipynb).
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import plotly.express as px # accessible module for plotting graphs
from scipy.stats import skew, kurtosis # to analyze the skew of our dataset
import plotly.figure_factory as ff

"""# Loading the GoFundMe Data

Below we load the GoFundMe data directly via its GitHub URL. Briefly take a look [at the data file](https://raw.githubusercontent.com/lmeninato/GoFundMe/master/data-raw/GFM_data.csv). You'll see that although the files ends in .csv, the fields are delimited (seperated) via a tab and not a comma. You'll see that I've flagged this for panda's read_csv() function using the `sep` argument and setting it equal to a tab (`\t`).


"""

df = pd.read_csv("https://raw.githubusercontent.com/lmeninato/GoFundMe/master/data-raw/GFM_data.csv", sep="\t")

"""# Let's explore the data file

1.   `show the first few rows of the data file.`
2.   List and describe the meaning of each row

The first row of the dataset is showing that $327345 has been raised for a 92 Year old man who was brutally attacked in Los Angeles, CA. This money was raised within one month by 12167 people.

The second row shows that $316261 has been raised for Olivia, who had a bone marrow transplant. This was raised within 3 months by 5598 people.

The second row shows that $241125 was rasied for a person who needed a T cell transplant in Staten Island, NY. This money was raised in 2 months by 841 people.
"""

df.head(5)

"""*list and description of column headers go here*

# Campaigns by Category



1.   `How many campaigns are in each category? Visuzlize this.`
2.   `What is the average $ amount raised in each category? Visualize this.`
3.   `What is the average fundraising goal in each category? Visualize this.`
4.   Provide a text summary of the results

*feel free to use multiple code blocks if you'd like*
"""

# here I am removing these numeric categories ... there are not categories
df_categories = df[~df['Category'].isin(['11525.0', '-75.3199035', '-73.9495823'])]

df_categories['Category'].value_counts().plot(kind ='barh', title='Number of Campaigns in each GoFundMe Category', xlabel='Number of campaigns', ylabel='Category')

"""1. There are 18 categories that GoFundMe Campaigns are in. The most campaigns are in the "Medical" category, at around 75 campaigns. The least amount of campaigns are in the "Animals" cateogry, at a little under 20 campaigns."""

category_means = df_categories.groupby('Category')['Amount_Raised'].mean()
category_means.plot(kind ='barh', title='Average Amount of Money Raised by GoFundMeCategory', xlabel='Average Money Raised ($)', ylabel='Category')

"""2. This is a distribution of the average amount of money raised in dollars for each GoFundMe category. The "Medical" category had the highest average of money raised at a around $150000. The "Competition" and "Newlywed" categories had the least average amount of money raised."""

df['Goal'] = df['Goal'].str.replace(',', '')
df['Goal'] = df['Goal'].str.replace('.', '')
df['Goal'] = df['Goal'].str.replace('M', '00000')
df['Goal'] = df['Goal'].str.replace('K', '00')
df['Goal'] = pd.to_numeric(df['Goal'])

# asked chatGPT to create a function to do this because I need to do this for a lot of variables
def convert_gfm_hearts(value):
    # Remove any whitespace and convert to uppercase
    value = str(value).strip().upper()

    # Check for 'M' (millions) and 'K' (thousands) notation
    if 'M' in value:
        return float(value.replace("M", "")) * 1_000_000
    elif 'K' in value:
        return float(value.replace("K", "")) * 1_000
    else:
        return float(value)  # Directly convert if no suffix

try:
    df['GFM_hearts'] = df['GFM_hearts'].apply(convert_gfm_hearts)
except ValueError as e:
    print("Conversion error:", e)

# Optional: Check for any remaining non-numeric values
df['GFM_hearts'] = pd.to_numeric(df['GFM_hearts'], errors='coerce')

# Display the converted column
print(df['GFM_hearts'].head())

try:
    df['FB_Shares'] = df['FB_Shares'].apply(convert_gfm_hearts)
except ValueError as e:
    print("Conversion error:", e)

# Optional: Check for any remaining non-numeric values
df['FB_Shares'] = pd.to_numeric(df['FB_Shares'], errors='coerce')

# Display the converted column
print(df['FB_Shares'].head())

df.head(10)

df = df[~df['Category'].isin(['11525.0', '-75.3199035', '-73.9495823'])]

goal_means = df.groupby('Category')['Goal'].mean()
goal_means.plot(kind = 'barh', title = 'Average Fundraising Goal by GoFundMe Category', xlabel='Average Fundraising Goal ($)', ylabel='Category')

"""3. Visually, there are similarities between the distribution of the average amount of money raised by category and the average fundraising goal by GoFundMe Category. We see that categories with higher average goals have higher amounts of money raised, and the same goes for categories with lower goals, so they raise less money. For example, the "Medical" category has the highest average fundraising goal at around $200,000 and the highest amount of money raised. The "Competition" category has a low goal and a low amount of money raised.

# Looking for outliers in shares and hearts



1.   `Select 3 catgories and create a boxplot of the FB shares and GFM hearts`
2.   `Plot the outliers in the boxplot`
1.   `Calculate the mean, median, mode, std deviation, and variance for the 3 categories' FB shares and GFM hearts`
3.   Summarize these results. What conclusions can you come to about these results?

1. Select categories and create visualizations.
2. Plot outliers within the boxplot.
"""

df_small = df[df['Category'].isin(['Medical', 'Family', 'Education'])]

fig = px.box(df_small, x = "Category", y = "FB_Shares", title = "Distribution of FaceBook Shares for GoFundMe Posts by Category")
fig.update_xaxes(title_text="Category")
fig.update_yaxes(title_text="Number of Facebook Shares")
fig.show()

"""There seem to be outliers in the education category for GoFundMe posts. It seems, on average, that most education GoFundMe posts do not have a lot of FB shares. But, there are a few times wehre education GoFundMes have been shared significantly more than the average."""

fig = px.box(df_small, x = "Category", y = "GFM_hearts", title = "Distribution of GoFundMe Hearts by Category")
fig.update_xaxes(title_text="Category")
fig.update_yaxes(title_text="Number of GFM Hearts")
fig.show()

"""There seems to be one outlier for the Education category, where one post received a great deal more GFM hearts than the average of all the education category posts.

In addition, within the family category, there are a few outliers. We see that there is a lower average of GFM hearts for Family posts, at atound 598 hearts; however, a few posts far surpassed this. These posts have around 400-900 likes, which is significnatly outside of the typical spread of the data.

3. Calculate descriptive statisics

Medical Category GB Shares Descriptive Statistics
"""

# select only the medical GoFundMe posts
df_small_medical = df_small[df_small['Category'] == 'Medical']

df_small_medical['FB_Shares'] = pd.to_numeric(df_small_medical['FB_Shares'], errors='coerce')

mean_value = df_small_medical['FB_Shares'].mean()
median_value = df_small_medical['FB_Shares'].median()
mode_value = df_small_medical['FB_Shares'].mode()[0] if not df_small_medical['FB_Shares'].mode().empty else None
std_deviation = df_small_medical['FB_Shares'].std()
variance = df_small_medical['FB_Shares'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""Medical Category GFM Hearts Descriptive Statistics"""

df_small_medical['GFM_hearts'] = pd.to_numeric(df_small_medical['GFM_hearts'], errors='coerce')


mean_value = df_small_medical['GFM_hearts'].mean()
median_value = df_small_medical['GFM_hearts'].median()
mode_value = df_small_medical['GFM_hearts'].mode()[0] if not df_small_medical['GFM_hearts'].mode().empty else None
std_deviation = df_small_medical['GFM_hearts'].std()
variance = df_small_medical['GFM_hearts'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""Education Category FaceBook Shares Descriptive Statistics


"""

df_small_Education = df_small[df_small['Category'] == 'Education']

df_small_Education['FB_Shares'] = pd.to_numeric(df_small_Education['FB_Shares'], errors='coerce')

mean_value = df_small_Education['FB_Shares'].mean()
median_value = df_small_Education['FB_Shares'].median()
mode_value = df_small_Education['FB_Shares'].mode()[0] if not df_small_Education['FB_Shares'].mode().empty else None
std_deviation = df_small_Education['FB_Shares'].std()
variance = df_small_Education['FB_Shares'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""Education Category GFM Hearts Descriptive Statistics"""

df_small_Education['GFM_hearts'] = pd.to_numeric(df_small_Education['GFM_hearts'], errors='coerce')

mean_value = df_small_Education['GFM_hearts'].mean()
median_value = df_small_Education['GFM_hearts'].median()
mode_value = df_small_Education['GFM_hearts'].mode()[0] if not df_small_Education['GFM_hearts'].mode().empty else None
std_deviation = df_small_Education['GFM_hearts'].std()
variance = df_small_Education['GFM_hearts'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""Family Category FaceBook Shares Descriptive Statistics"""

df_small_Family = df_small[df_small['Category'] == 'Family']

df_small_Family['FB_Shares'] = pd.to_numeric(df_small_Family['FB_Shares'], errors='coerce')

mean_value = df_small_Family['FB_Shares'].mean()
median_value = df_small_Family['FB_Shares'].median()
mode_value = df_small_Family['FB_Shares'].mode()[0] if not df_small_Family['FB_Shares'].mode().empty else None
std_deviation = df_small_Family['FB_Shares'].std()
variance = df_small_Family['FB_Shares'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""Family Category GFM Hearts Descriptive Statistics"""

df_small_Family['GFM_hearts'] = pd.to_numeric(df_small_Family['GFM_hearts'], errors='coerce')

mean_value = df_small_Family['GFM_hearts'].mean()
median_value = df_small_Family['GFM_hearts'].median()
mode_value = df_small_Family['GFM_hearts'].mode()[0] if not df_small_Family['GFM_hearts'].mode().empty else None
std_deviation = df_small_Family['GFM_hearts'].std()
variance = df_small_Family['GFM_hearts'].var()

print(mean_value)
print(median_value)
print(mode_value)
print(std_deviation)
print(variance)

"""4. Summarize results.

The medical category has the greatest average of FB shares, followed by the family category, then the education category. In addition, the medical category has the greatest average of GoFundMe likes, followed by the family category, then the education category. This might be because of the urgency associated with getting medical treatments done, which means that money needs to be raised in a shorter period of time, leading to a faster spread of awareness by the people. The family category seems to have the greatest variance within the data, meaning that values are spread out more from the average number of GFM hearts within this category.

**Part 2 of the Homework**

1. Visualizations of GFM Heart by Category showing Unsuccessful and Successful Projects
"""

# here I created two dataframe: one with successful projects, one with unsuccessful projects

df['Amount_Raised'] = pd.to_numeric(df['Amount_Raised'], errors='coerce')
df['Goal'] = pd.to_numeric(df['Goal'], errors='coerce')
df_suc = df[df['Amount_Raised'] >= df['Goal']]
df_unsuc = df[df['Amount_Raised'] < df['Goal']]

df_suc.head(5)

df_unsuc.head(5)

import seaborn as sns

g_unsuc = sns.catplot(x="Category", y="GFM_hearts", data=df_unsuc, kind="bar", height=6, aspect=1.5)
g_unsuc.set_xticklabels(rotation=90)
g_unsuc.set_axis_labels("Category", "GFM Hearts")
g_unsuc.fig.suptitle("GFM Hearts by Category for Unsuccessful Projects", y=1.05)

g_suc = sns.catplot(x="Category", y="GFM_hearts", data=df_suc, kind="bar", height=6, aspect=1.5)
g_suc.set_xticklabels(rotation=90)
g_suc.set_axis_labels("Category", "GFM Hearts")
g_suc.fig.suptitle("GFM Hearts by Category for Successful Projects", y=1.05)

"""2. Visualizing the Relationship between Successful Projects in relation to Length of Fundraising"""

df['Success'] = (df['Amount_Raised'] >= df['Goal']).astype(int)
df['Success'] = df['Success'].replace({0: 'Unsuccessful', 1: 'Successful'})
# I had to use chat gpt to figure out how to rename the 0 and 1 to make this reflect
# correctly in my legend. i was having difficulty using the code in the documentation to
# override these names.

# convert length of fundraising variable into days. Here, I used Chat GPT
# to create a function to convert all lengths to days. I had issues at first
# because some lengths were saying "months" or "days," so the data was not
# normalized.
import re

def convert_to_days(length_str):
    if isinstance(length_str, str):
        # Extract the numeric part and the unit (days or month)
        match = re.match(r'(\d+)\s*(\w+)', length_str.strip().lower())
        if match:
            length = int(match.group(1))
            unit = match.group(2)

            # Convert based on the unit
            if unit in ['month', 'months']:  # If the unit is months
                return length * 30  # Convert months to days
            elif unit in ['day', 'days']:  # If the unit is days
                return length  # Leave days as is
    return None

df['Length_of_Fundraising'] = df['Length_of_Fundraising'].apply(lambda x: convert_to_days(x) if isinstance(x, str) else None)

df.head(5)

fig = px.histogram(df, x = "Length_of_Fundraising", color = "Success",
                   title = "Length of Fundraising by Success")
fig.update_xaxes(title_text="Length of Fundraising (days)")
fig.update_yaxes(title_text="Frequency of Successes")

fig = px.box(df, x = "Success", y = "Length_of_Fundraising", color = "Success",
                   title = "Length of GoFundMe Fundraising by Success")
fig.update_xaxes(title_text="GFM Project Success")
fig.update_yaxes(title_text="Length of Fundraising (days)")

fig = px.histogram(df, x="Length_of_Fundraising", color="Success",
                   title="Duration (in days) of Fundraising for GoFundMe Posts by Success",
                   barmode="group",
                   labels={"Length_of_Fundraising": "Length of Fundraising (days)",
                           "Success": "Success"})
fig.update_xaxes(title_text="Length of Fundraising (days)")
fig.update_yaxes(title_text="Frequency")
fig.show()

"""Looking at the first two distributions, we can see that that majority of posts seem to be split between being successful and unsuccessful. It almost seems as though there is no relationship between whether a GoFundMe post is successful or not based on the length it has been posted in days.

I wanted to explore this relationship further, so I created a side-by-side histogram.Here we can see that there are consistently more unsuccessful posts on average, regardless of the length of fundraising.

3. Visualizing the Relationship Between Successful Projects and FB Shares
"""

fig = px.box(df, x = "Success", y = "FB_Shares", color = "Success",
                   title = "Frequency of FaceBook Shares of GoFundMe Posts by Success")
fig.update_xaxes(title_text="GFM Project Success")
fig.update_yaxes(title_text="FB Shares")

fig = px.histogram(df, x = "FB_Shares", color = "Success",
                   title = "Distribution of FaceBook Shares of GoFundMe Posts by Success")
fig.update_xaxes(title_text="Number of FaceBook Shares")
fig.update_yaxes(title_text="Frequency")

# I chose to remove outliers to better visualize trends
df_filtered = df[df['FB_Shares'] <= 15000]

fig = px.box(df_filtered, x = "Success", y = "FB_Shares", color = "Success",
                   title = "Frequency of FaceBook Shares of GoFundMe Posts by Success")
fig.update_xaxes(title_text="GFM Project Success Status")
fig.update_yaxes(title_text="FB Shares")

fig = px.histogram(df_filtered, x="FB_Shares", color="Success",
                   title="Distribution of FaceBook Shares of GoFundMe Posts by Success")

fig.update_xaxes(title_text="Number of Facebook Shares")
fig.update_yaxes(title_text="Frequency")
fig.show()

fig = px.histogram(df_filtered, x="FB_Shares", color="Success",
                   title="Distribution of FaceBook Shares of GoFundMe Posts by Success",
                   barmode="group",
                   labels={"Length_of_Fundraising": "Length of Fundraising (days)",
                           "Success": "Success Status"})
fig.update_xaxes(title_text="Number of FB Shares")
fig.update_yaxes(title_text="Frequency")
fig.show()

"""It seems as though majority of posts are unsuccessful. We do see, however, that the highest amount of unsuccessful posts are those with 0 FaceBook shares. Outliers within the boxplots illustrate that a few posts with a significant number of more facebook shares are successful.

4. Ratio of Success vs Unsuccessful projects by Category
"""

success_ratio = df.groupby(['Category', 'Success']).size().reset_index(name='Count')

fig = px.bar(success_ratio, x="Category", y="Count", color="Success",
             title="Successful:Unsuccessful Projects by GoFundMe Category",
             labels={"Count": "Number of Projects",
                     "Success": "Success Status"},
             barmode='stack')
fig.show()

"""It seems that majority of GoFundMe projects are unsuccessful, regardless of category. However, we do see that the most successful projects seem to be Event GoFundMe projects."""